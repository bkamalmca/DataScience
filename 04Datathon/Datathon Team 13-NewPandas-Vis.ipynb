{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datathon Team 13\n",
    "\n",
    "9/20/2021\n",
    "\n",
    "**Problem definition:** Want to predict turnaround time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pandas\n",
    "!pip install geopy\n",
    "!pip install xgboost\n",
    "!pip install holidays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "### Load packages\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import date, datetime\n",
    "import random\n",
    "from geopy.distance import distance\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "import holidays\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", 500)\n",
    "outputs = []\n",
    "\n",
    "def clean_data(thisDf): \n",
    "    thisDf['ORDER_CODE'] = thisDf['ORDER_CODE'].astype(str)\n",
    "    # remove anything with a negative TAT\n",
    "#     thisDf = thisDf[(thisDf['TAT_HOUR']>=0) | (thisDf['TAT_HOUR'].isnull())]\n",
    "#     # remove anything that is over the 99th percentile\n",
    "#     thisDf = thisDf[(thisDf['TAT_HOUR']<=thisDf['TAT_HOUR'].quantile(.99)) | (thisDf['TAT_HOUR'].isnull())]\n",
    "    return thisDf\n",
    "    \n",
    "def initial_drop_columns(thisDf): \n",
    "    return thisDf.drop([\n",
    "        #'RECORD_ID',\n",
    "        'PERFORMING_LAB_NAME',\n",
    "        'BU_NAME',\n",
    "        #'BU_LATITUDE',\n",
    "        #'BU_LONGITUDE',\n",
    "        'ORDERING_LAB_CODE',\n",
    "        'ORDERING_LAB_NAME',     \n",
    "        'BILLING_LEGAL_ENTITY',\n",
    "        'ACCOUNT_NUMBER',\n",
    "        'ACCOUNT_NAME',\n",
    "        'ACCOUNT_STATE',\n",
    "        'ACCOUNT_ZIP_CODE',\n",
    "        'SPECIALTY_DESC',\n",
    "        'PHYSICIAN_NPI',\n",
    "        'PHYSICIAN_NAME',\n",
    "        'BILL_ONLY_INDICATOR',\n",
    "        'ORDER_UNIT_CODE',#come back to this \n",
    "        'ORDER_NAME',\n",
    "        'ORDER_CODE_MNEMONIC',\n",
    "        'PUBLISHED_TAT',\n",
    "        'MAX_TAT',\n",
    "        'STAT_ROUTINE_INDICATOR'   \n",
    "    ], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "def get_distances(thisDf):\n",
    "\n",
    "    def geo_distance(x):\n",
    "\n",
    "        try: \n",
    "            return distance( (x['PERFORMING_LAB_LATITUDE'], x['PERFORMING_LAB_LONGITUDE']),\n",
    "                               (x['ORDERING_LAB_LATITUDE'], x['ORDERING_LAB_LONGITUDE'])\n",
    "                           ).miles\n",
    "        except:\n",
    "            return 0\n",
    "        \n",
    "    try:\n",
    "        thisDf['Distance'] = thisDf.progress_apply(geo_distance, axis=1)\n",
    "    except:\n",
    "        thisDf['Distance'] = thisDf.apply(geo_distance, axis=1)\n",
    "    return thisDf\n",
    "\n",
    "def do_concats(thisDf): \n",
    "    # df_t['Lab_Order'] = df_t['LAB_SYSTEM_ID'].astype(str) + df_t['ORDER_CODE'].astype(str)\n",
    "    # df_t['Performing_Lab'] = df_t['PERFORMING_LAB_SITE_TYPE'].astype(str) + df_t['PERFORMING_LAB_CODE'].astype(str)\n",
    "\n",
    "    return thisDf\n",
    "\n",
    "def update_add_on_exists(thisDf):\n",
    "    thisDf['Add_On_Exists'] =thisDf['ADD_ON_ORDER_DATE'].isnull()\n",
    "    thisDf['Add_On_Exists'] =thisDf['Add_On_Exists'].apply(lambda x: 0 if x is True else 1)\n",
    "    return thisDf\n",
    "\n",
    "def do_date_stuff(thisDf):\n",
    "#     def day_of_week(x):\n",
    "#         return x.day_name()\n",
    "\n",
    "    thisDf['COLLECTION_DATE'] = pd.to_datetime(thisDf['COLLECTION_DATE'])\n",
    "    thisDf['ACCESSION_DATE'] = pd.to_datetime(thisDf['ACCESSION_DATE'])\n",
    "    thisDf['Collection_DOW'] = thisDf['COLLECTION_DATE'].dt.day_name()\n",
    "    thisDf['Accession_DOW'] = thisDf['ACCESSION_DATE'].dt.day_name()\n",
    "    \n",
    "    #check to see if holiday\n",
    "    us_holidays = holidays.US()\n",
    "    \n",
    "    thisDf['Accession_is_Holiday'] = thisDf['ACCESSION_DATE'].apply(lambda x: x in us_holidays)\n",
    "    thisDf['Collection_is_Holiday'] = thisDf['COLLECTION_DATE'].apply(lambda x: x in us_holidays)\n",
    "    thisDf['Collection_is_Holiday'] = thisDf['Collection_is_Holiday'].apply(lambda x: 1 if x is True else 0)\n",
    "    thisDf['Accession_is_Holiday'] = thisDf['Accession_is_Holiday'].apply(lambda x: 1 if x is True else 0)\n",
    "    \n",
    "    \n",
    "    # get collection hour\n",
    "    thisDf['Collection_Hour'] = thisDf['COLLECTION_DATE'].dt.hour\n",
    "    \n",
    "    # do hours between collection/accession\n",
    "    thisDf['Hours_Collection_to_Accession'] = thisDf['ACCESSION_DATE'] - thisDf['COLLECTION_DATE']\n",
    "    thisDf['Hours_Collection_to_Accession'] = thisDf['Hours_Collection_to_Accession'].dt.total_seconds()/60/60\n",
    "    \n",
    "    thisDf['Bad_Accession_Date'] = thisDf['COLLECTION_DATE'] > thisDf['ACCESSION_DATE'] \n",
    "    thisDf['Bad_Accession_Date'] = thisDf['Bad_Accession_Date'].apply(lambda x: 1 if x is True else 0)\n",
    "\n",
    "    \n",
    "    return thisDf\n",
    "\n",
    "def second_drop_columns(thisDf):\n",
    "    return thisDf.drop(\n",
    "        [\n",
    "            'PERFORMING_LAB_LATITUDE',\n",
    "            'PERFORMING_LAB_LONGITUDE',\n",
    "            'ORDERING_LAB_LATITUDE',\n",
    "            'ORDERING_LAB_LONGITUDE',\n",
    "            'BU_LATITUDE',\n",
    "            'BU_LONGITUDE',\n",
    "            'COLLECTION_DATE',\n",
    "            'ACCESSION_DATE',\n",
    "            'ADD_ON_ORDER_DATE',\n",
    "            'WORKLIST_CODE',\n",
    "            'PERFORMING_LAB_SITE_TYPE',\n",
    "            #'ORDER_CODE',\n",
    "            #'PERFORMING_LAB_CODE',\n",
    "        ], axis=1)\n",
    "\n",
    "def get_dummy_vars(thisDf):\n",
    "    return pd.get_dummies(thisDf, drop_first = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "### Load data\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "s3_bucket = 'dgx-datathon-data/validation'\n",
    "filename = 'datathon_validation.tab'\n",
    "data_location = 's3://{}/{}'.format(s3_bucket, filename)\n",
    "\n",
    "df_validation_ = pd.read_csv(data_location, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "s3_bucket = 'dgx-datathon-data/full'\n",
    "filename = 'datathon.tab'\n",
    "data_location = 's3://{}/{}'.format(s3_bucket, filename)\n",
    "\n",
    "df_ = pd.read_csv(data_location, sep='\\t')\n",
    "df_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.sample(n=1000000, random_state=42)\n",
    "# df.shape\n",
    "# df.to_csv('df_sample_1m.csv', index=False)\n",
    "# df.to_csv('s3://dgx-team13-s3/nasser-autopilot/df_sample_1m.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_validation_.shape)\n",
    "print(df_.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate validation and regular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "df_validation = df_validation_.copy()\n",
    "df = df_.copy()\n",
    "df['Source'] = 'Full'\n",
    "df_validation['Source'] = 'Evaluation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_validation, df])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "## Checkpoint 0\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "### Initial cleaning of data\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial data column drops\n",
    "df = initial_drop_columns(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "### Transformations on the data\n",
    "</div>\n",
    "\n",
    "* number of times specimen is collected, as well as actual specimen collection time\n",
    "    * also look for morning/afternoon/evening\n",
    "* find when BU region is different from performing (binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "## Checkpoint 1\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t = clean_data(df_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t = do_concats(df_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "df_lat_lon = df_t[['PERFORMING_LAB_LATITUDE', 'PERFORMING_LAB_LONGITUDE', 'ORDERING_LAB_LATITUDE', 'ORDERING_LAB_LONGITUDE']]\n",
    "df_lat_lon.drop_duplicates(inplace=True)\n",
    "df_lat_lon = get_distances(df_lat_lon)\n",
    "\n",
    "df_t = pd.merge(\n",
    "    df_t,\n",
    "    df_lat_lon,\n",
    "    on=['PERFORMING_LAB_LATITUDE', 'PERFORMING_LAB_LONGITUDE', 'ORDERING_LAB_LATITUDE', 'ORDERING_LAB_LONGITUDE'],\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t = update_add_on_exists(df_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "df_t = do_date_stuff(df_t)\n",
    "# morning/afternoon/evening transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "## Checkpoint !!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECKPOINT\n",
    "df_checkpoint = df_t.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_t.shape)\n",
    "df_t['Source'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial data column drops\n",
    "df_t = second_drop_columns(df_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get an idea of how many new features we'll get from dummy explosion\n",
    "for col in list(df_t):\n",
    "    if (df_t[col].dtype =='object'):\n",
    "        print('col:', col, 'unique vals: ', df_t[col].nunique() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.boxplot(df_t[df_t['TAT_HOUR']<=df_t['TAT_HOUR'].quantile(.95)][['TAT_HOUR',  'PERFORMING_REGION']].sample(2000))\n",
    "plt.figure(figsize = (15,6))\n",
    "sns.set(font_scale=1.0)\n",
    "sns.boxplot(x=\"MARKET_SEGMENT_DESC\", y=\"TAT_HOUR\", data=df_t[['TAT_HOUR',  'MARKET_SEGMENT_DESC']].sample(200000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.boxplot(df_t[df_t['TAT_HOUR']<=df_t['TAT_HOUR'].quantile(.95)][['TAT_HOUR',  'PERFORMING_REGION']].sample(2000))\n",
    "plt.figure(figsize = (8,6))\n",
    "sns.set(font_scale=1.0)\n",
    "sns.boxplot(x=\"Collection_Hour\", y=\"TAT_HOUR\", data=df_t[['TAT_HOUR',  'Collection_Hour']].sample(200000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.boxplot(df_t[df_t['TAT_HOUR']<=df_t['TAT_HOUR'].quantile(.95)][['TAT_HOUR',  'PERFORMING_REGION']].sample(2000))\n",
    "plt.figure(figsize = (13,6))\n",
    "sns.set(font_scale=1.0)\n",
    "sns.boxplot(x=\"PERFORMING_REGION\", y=\"TAT_HOUR\", data=df_t[['TAT_HOUR',  'PERFORMING_REGION']].sample(200000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#sns.boxplot(df_t[df_t['TAT_HOUR']<=df_t['TAT_HOUR'].quantile(.95)][['TAT_HOUR',  'PERFORMING_REGION']].sample(2000))\n",
    "plt.figure(figsize = (3,6))\n",
    "sns.set(font_scale=1.0)\n",
    "sns.boxplot(x=\"Collection_is_Holiday\", y=\"TAT_HOUR\", data=df_t[['TAT_HOUR',  'Collection_is_Holiday']].sample(200000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#sns.boxplot(df_t[df_t['TAT_HOUR']<=df_t['TAT_HOUR'].quantile(.95)][['TAT_HOUR',  'PERFORMING_REGION']].sample(2000))\n",
    "plt.figure(figsize = (8,6))\n",
    "sns.set(font_scale=1.0)\n",
    "sns.boxplot(x=\"Collection_DOW\", y=\"TAT_HOUR\", data=df_t[['TAT_HOUR',  'Collection_DOW']].sample(200000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#sns.boxplot(df_t[df_t['TAT_HOUR']<=df_t['TAT_HOUR'].quantile(.95)][['TAT_HOUR',  'PERFORMING_REGION']].sample(2000))\n",
    "plt.figure(figsize = (12,6))\n",
    "sns.set(font_scale=1.0)\n",
    "sns.boxplot(x=\"LAB_SYSTEM_ID\", y=\"TAT_HOUR\", data=df_t[['TAT_HOUR',  'LAB_SYSTEM_ID']].sample(200000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.boxplot(df_t[df_t['TAT_HOUR']<=df_t['TAT_HOUR'].quantile(.95)][['TAT_HOUR',  'PERFORMING_REGION']].sample(2000))\n",
    "plt.figure(figsize = (12,6))\n",
    "sns.set(font_scale=1.0)\n",
    "sns.boxplot(x=\"ORDERING_LAB_SITE_TYPE\", y=\"TAT_HOUR\", data=df_t[['TAT_HOUR',  'ORDERING_LAB_SITE_TYPE']].sample(200000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,12))\n",
    "sns.set(font_scale=1.1)\n",
    "sns.pairplot(df_t[['TAT_HOUR', 'Distance', 'Collection_Hour', 'Hours_Collection_to_Accession', 'PERFORMING_REGION']].sample(10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8,2))\n",
    "sns.set(font_scale=1.1)\n",
    "\n",
    "sns.heatmap(df_t[df_t['TAT_HOUR']<=df_t['TAT_HOUR'].quantile(.95)][['TAT_HOUR', 'Distance', 'Collection_Hour', 'Hours_Collection_to_Accession']].sample(2000).corr(), annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "## Checkpoint !!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_checkpoint_2 = df_t.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_t = get_dummy_vars(df_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "### Building the model\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "# separate labeled data\n",
    "df_labeled = df_t[df_t['Source_Full']==1].copy()\n",
    "df_labeled.drop(['Source_Full'], axis=1, inplace=True)\n",
    "\n",
    "# of labeled data, get a 3M samples that will be used for train/test\n",
    "df_model = df_labeled.sample(n=3000000, random_state=42)\n",
    "\n",
    "# get the data that will not be used for train/test for validation\n",
    "training_test_ids = list(df_model['RECORD_ID'])\n",
    "df_validation = df_labeled[~df_labeled['RECORD_ID'].isin(training_test_ids)]\n",
    "\n",
    "# this is what we wil be evaluated on\n",
    "df_model_eval = df_t[df_t['Source_Full']==0].copy()\n",
    "df_model_eval.drop(['Source_Full'], axis=1, inplace=True)\n",
    "\n",
    "# drop record IDs\n",
    "df_model.drop(['RECORD_ID'], axis=1, inplace=True)\n",
    "df_model_eval.drop(['RECORD_ID'], axis=1, inplace=True)\n",
    "\n",
    "print(df_labeled.shape)\n",
    "print(df_model.shape)\n",
    "print(df_validation.shape)\n",
    "print(df_model_eval.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "# get data in array format because that's what ML models prefer\n",
    "X = np.array(df_model.drop(['TAT_HOUR'], axis=1)).astype('float32')\n",
    "y = np.array(df_model['TAT_HOUR']).astype('float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "y = y.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "model = xgb.XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    learning_rate=None,\n",
    "    max_depth=None,\n",
    "#     reg_lambda=0.04328041793594834,\n",
    "#     min_child_weight=22.356147665843558,\n",
    "#     gamma=33.61489625428083,\n",
    "    n_estimators=100    \n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "model_score = model.score(X_test, y_test)\n",
    "print(model_score)\n",
    "\n",
    "y_predict = model.predict(X_test)\n",
    "k = X_test.shape[1]\n",
    "n = len(X_test)\n",
    "RMSE = float(format(np.sqrt(mean_squared_error(y_test, y_predict)),'.3f'))\n",
    "MSE = mean_squared_error(y_test, y_predict)\n",
    "MAE = mean_absolute_error(y_test, y_predict)\n",
    "r2 = r2_score(y_test, y_predict)\n",
    "adj_r2 = 1-(1-r2)*(n-1)/(n-k-1)\n",
    "\n",
    "print('RMSE =',RMSE, '\\nMSE =',MSE, '\\nMAE =',MAE, '\\nR2 =', r2, '\\nAdjusted R2 =', adj_r2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_score = model.score(X_test, y_test)\n",
    "notes = 'BASELINE'\n",
    "now = datetime.now() # current date and time\n",
    "time = now.strftime(\"%m_%d_%Y__%H_%M_%S\")\n",
    "\n",
    "outputs.append([    \n",
    "    time,\n",
    "    model.__dict__['n_estimators'],\n",
    "    model.__dict__['max_depth'],\n",
    "    model.__dict__['learning_rate'],\n",
    "    model_score,\n",
    "    X.shape,\n",
    "    notes]\n",
    ")\n",
    "\n",
    "\n",
    "df_outputs = pd.read_csv('outputs.csv')\n",
    "df_outputs = pd.concat([   \n",
    "    df_outputs,\n",
    "    pd.DataFrame(outputs, columns=['time','n_estimators', 'max_depth', 'learning_rate', 'accuracy', 'X shape', 'notes']),\n",
    "])\n",
    "df_outputs.drop_duplicates(inplace=True)\n",
    "df_outputs.to_csv('outputs.csv', index=False)\n",
    "df_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in list(df_validation_1m):\n",
    "    if col not in list(df_model):\n",
    "        print(col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "df_validation_1m = df_validation.head(1000000)\n",
    "\n",
    "X_validation = np.array(df_validation_1m.drop(['RECORD_ID','TAT_HOUR'], axis=1)).astype('float32')\n",
    "y_validation = np.array(df_validation_1m['TAT_HOUR']).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "y_hat_validation = model.predict(X_validation)\n",
    "r2_score(y_hat_validation.astype(int), y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validation_1m['y_hat']=y_hat_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validation_1m[['y_hat','TAT_HOUR']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "X_evaluation = np.array(df_model_eval.drop(['TAT_HOUR'], axis=1)).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_evaluation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_evaluation = model.predict(X_evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_eval = df_t[df_t['Source_Full']==0].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_eval['TAT_HOUR']=y_hat_evaluation.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_eval.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.merge(\n",
    "    df_validation_,\n",
    "    df_model_eval[['RECORD_ID','TAT_HOUR']],\n",
    "    on='RECORD_ID',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "#df_final.to_csv('s3://dgx-team13-s3/nasser-autopilot/df_evaluation.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_SUBMIT = df_model_eval[['RECORD_ID','TAT_HOUR']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_SUBMIT.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prev = pd.read_csv('s3://dgx-team13-s3/nasser-autopilot/df_evaluation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_SUBMIT.head()\n",
    "df_SUBMIT.to_csv('s3://dgx-team13-s3/nasser-autopilot/Team13_prediction.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pass validation data through model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_SUBMIT.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_SUBMIT.head()\n",
    "df_SUBMIT.to_csv('s3://dgx-team13-s3/submission/Team13_prediction.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#sns.boxplot(df_t[df_t['TAT_HOUR']<=df_t['TAT_HOUR'].quantile(.95)][['TAT_HOUR',  'PERFORMING_REGION']].sample(2000))\n",
    "plt.figure(figsize = (12,6))\n",
    "sns.set(font_scale=1.0)\n",
    "sns.boxplot(x=\"LAB_SYSTEM_ID\", y=\"TAT_HOUR\", data=df_final[['TAT_HOUR',  'LAB_SYSTEM_ID']].sample(200000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.drop(['TAT_HOUR_x'], inplace=True, axis=1)\n",
    "df_final['TAT_HOUR'] = df_final['TAT_HOUR_y']"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
