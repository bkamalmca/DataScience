{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import boto3, re, sys, math, json, os, sagemaker, urllib.request\n",
    "from sagemaker import get_execution_role\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "from IPython.display import display\n",
    "from time import gmtime, strftime\n",
    "from sagemaker.predictor import csv_serializer\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "# Define IAM role\n",
    "role = get_execution_role()\n",
    "bucket_name = 'dgx-ds-use1-dev-landing-s3'\n",
    "prefix = 'kamal/OrderTAT-xgboost'\n",
    "my_region = boto3.session.Session().region_name # set the region of the instance\n",
    "\n",
    "# this line automatically looks for the XGBoost image URI and builds an XGBoost container.\n",
    "#xgboost_container = sagemaker.image_uris.retrieve(\"xgboost\", my_region, \"latest\")\n",
    "xgboost_container = get_image_uri(my_region, \"xgboost\", \"1.2-2\")\n",
    "\n",
    "print(\"Success - the MySageMakerInstance is in the \" + my_region + \" region. You will use the \" + xgboost_container + \" container for your SageMaker endpoint.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_key = 'kamal/input/order_data_prep_job1.csv' \n",
    "data_location = 's3://{}/{}'.format(bucket_name, data_key) \n",
    "\n",
    "try:\n",
    "  df = pd.read_csv(data_location, index_col=0)\n",
    "  print('Success: Data loaded into dataframe.')\n",
    "except Exception as e:\n",
    "    print('Data load error: ',e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#target encoding\n",
    "#df['TAT_HOUR'].mean()\n",
    "df['ORDER_ENC'] = df.groupby('ORDER_CODE_N')['TAT_HOUR'].transform('mean')\n",
    "df['ORDER_ENC'] = round((0.6 * df['ORDER_ENC']) + (0.4 * df['TAT_HOUR'].mean()),2)\n",
    "df.drop('ORDER_CODE_N', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "model_data = pd.get_dummies(df, drop_first = True)\n",
    "model_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=[]\n",
    "model_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#large not working for 2.4M\n",
    "model_data = model_data.sample(n=2000000, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = np.split(model_data.sample(frac=1, random_state=42), [int(0.8 * len(model_data))])\n",
    "print(train_data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "data_key = prefix + '/train/train.csv' \n",
    "data_location = 's3://{}/{}'.format(bucket_name, data_key) \n",
    "\n",
    "train_data.to_csv(data_location, index=False, header=False)\n",
    "s3_input_train = sagemaker.inputs.TrainingInput(s3_data='s3://{}/{}/train'.format(bucket_name, prefix), content_type='csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "dt_string = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "print(\"date and time =\", dt_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = sagemaker.Session()\n",
    "xgb = sagemaker.estimator.Estimator(              \n",
    "                xgboost_container,\n",
    "                role, \n",
    "                instance_count=1, \n",
    "                base_job_name='kamal-sagemaker-orderTAT-xgb-2xl-', \n",
    "                instance_type='ml.m5.2xlarge',\n",
    "                output_path='s3://{}/{}/output'.format(bucket_name, prefix),\n",
    "                sagemaker_session=sess)\n",
    "xgb.set_hyperparameters(\n",
    "                max_depth=6,\n",
    "                eta=0.2,\n",
    "                gamma=4,\n",
    "                min_child_weight=6,\n",
    "                subsample=0.8,\n",
    "                #silent=0,\n",
    "                objective='reg:squarederror',\n",
    "                num_round=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.fit({'train': s3_input_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model store\n",
    "data_key = prefix + '/model/modelXGB' \n",
    "model_loc = 's3://{}/{}'.format(bucket_name, data_key) \n",
    "print(model_loc)\n",
    "\n",
    "import pickle\n",
    "with open('modelXGB','wb') as file:\n",
    "    pickle.dump(xgb,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predictor = xgb.deploy(initial_instance_count=1,instance_type='ml.m5.large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "test_data_p = test_data.sample(n=3000)\n",
    "test_data_array = test_data_p.drop(['TAT_HOUR'], axis=1).values #load the data into an array\n",
    "xgb_predictor.serializer = CSVSerializer() # set the serializer type\n",
    "predictions = xgb_predictor.predict(test_data_array).decode('utf-8') # predict!\n",
    "predictions_array = np.fromstring(predictions[1:], sep=',') # and turn the prediction into an array\n",
    "print(predictions_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import explained_variance_score, r2_score, mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "\n",
    "model_score = explained_variance_score(test_data_p['TAT_HOUR'], predictions_array)\n",
    "print(\"Score = \",model_score)\n",
    "\n",
    "k = test_data_p.shape[1]\n",
    "n = len(test_data_p)\n",
    "MSE = mean_squared_error(test_data_p['TAT_HOUR'], predictions_array)\n",
    "MAE = mean_absolute_error(test_data_p['TAT_HOUR'], predictions_array)\n",
    "r2 = r2_score(test_data_p['TAT_HOUR'], predictions_array)\n",
    "adj_r2 = 1-(1-r2)*(n-1)/(n-k-1)\n",
    "#print(\"MSE: %.2f\" % MSE)\n",
    "#print(\"RMSE: %.2f\" % (mse**(1/2.0)))\n",
    "print('RMSE =',(MSE**(1/2.0)), '\\nMSE =',MSE, '\\nMAE =',MAE, '\\nR2 =', r2, '\\nAdjusted R2 =', adj_r2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_ax = range(len(test_data_p['TAT_HOUR']))\n",
    "plt.scatter(test_data_p['TAT_HOUR'], predictions_array, s=5, color=\"blue\", label=\"original\")\n",
    "plt.plot(x_ax, predictions_array, lw=0.8, color=\"red\", label=\"predicted\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete manually in dashboard\n",
    "#xgb_predictor.delete_endpoint(delete_endpoint_config=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bucket_to_delete = boto3.resource('s3').Bucket(bucket_name)\n",
    "#bucket_to_delete.objects.all().delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch transform\n",
    "data_key = prefix + '/test' \n",
    "batch_input = 's3://{}/{}'.format(bucket_name, data_key) \n",
    "\n",
    "data_key2 = prefix + '/batch-predict' \n",
    "batch_output = 's3://{}/{}'.format(bucket_name, data_key2) \n",
    "\n",
    "print(batch_input)\n",
    "print(batch_output)\n",
    "\n",
    "test_data.drop(['TAT_HOUR'], axis=1).to_csv(batch_input + '/test.csv',index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "transformer = xgb.transformer(\n",
    "    instance_count=1, \n",
    "    instance_type='ml.m5.2xlarge', \n",
    "    output_path=batch_output\n",
    ")\n",
    "\n",
    "transformer.transform(\n",
    "    data=batch_input, \n",
    "    data_type='S3Prefix',\n",
    "    content_type='text/csv', \n",
    "    split_type='Line'\n",
    ")\n",
    "transformer.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_key2 = prefix + '/batch-predict/test.csv.out' \n",
    "batch_output = 's3://{}/{}'.format(bucket_name, data_key2) \n",
    "pred_y = pd.read_csv(batch_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import explained_variance_score, r2_score, mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "\n",
    "model_score = explained_variance_score(test_data['TAT_HOUR'][1:], pred_y)\n",
    "print(\"Score = \",model_score)\n",
    "\n",
    "k = test_data.shape[1]\n",
    "n = len(test_data)\n",
    "MSE = mean_squared_error(test_data['TAT_HOUR'][1:], pred_y)\n",
    "MAE = mean_absolute_error(test_data['TAT_HOUR'][1:], pred_y)\n",
    "r2 = r2_score(test_data['TAT_HOUR'][1:], pred_y)\n",
    "adj_r2 = 1-(1-r2)*(n-1)/(n-k-1)\n",
    "#print(\"MSE: %.2f\" % MSE)\n",
    "#print(\"RMSE: %.2f\" % (mse**(1/2.0)))\n",
    "print('RMSE = ',(MSE**(1/2.0)), '\\nMSE =',MSE, '\\nMAE =',MAE, '\\nR2 =', r2, '\\nAdjusted R2 =', adj_r2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read model from s3\n",
    "modelx = sagemaker.model.Model(\n",
    "    image_uri=xgboost_container,\n",
    "    model_data ='s3://dgx-ds-use1-dev-landing-s3/kamal/OrderTAT-xgboost/output/sagemaker-xgboost-2021-10-26-03-08-13-506/output/model.tar.gz',\n",
    "    role=role)\n",
    "\n",
    "print(modelx)"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.m5.xlarge",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
